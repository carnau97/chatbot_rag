{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faeb271b",
   "metadata": {},
   "source": [
    "# Pinecone - Creando un asistente conversacional\n",
    "\n",
    "### Arquitectura RAG\n",
    "\n",
    "## Introducci칩n <a name=\"intro\"></a>\n",
    "\n",
    "El prop칩sito general de este notebook es generar un asistente conversacional basado en la arquitectura RAG (_Retrieval Augmented Generation_).\n",
    "\n",
    "1. Dispondremos de unos documentos PDFs que ser치n nuestra base de conocimiento, los cu치les vectorizaremos y almacenaremos como Embeddings en un 칤ndice de Pinecone\n",
    "2. Posteriormente, a trav칠s de LangChain podremos lanzar queries y que autom치ticamente se pasen por el modelo de embedding y se conecten al 칤ndice de Pinecone para hacer una b칰squeda por similitud, para posteriormente pasarle los trozos m치s relevantes al LLM para que nos devuelva una respuesta.\n",
    "\n",
    "## LangChain 游붚 <a name=\"langchain\"></a>\n",
    "\n",
    "__LangChain__ es un marco para desarrollar aplicaciones basadas en modelos del lenguaje (칰nicamente se especializa en NLP)\n",
    "\n",
    "Para instalar LangChain en Python haremos:\n",
    "\n",
    "```python\n",
    "!pip install langchain\n",
    "```\n",
    "\n",
    "Adem치s de permitirnos encadenar conversaciones, LangChain tiene distintas funciones para leer archivos y hacer las divisiones de los textos en chunks\n",
    "\n",
    "El m칩dulo `document_loaders` https://python.langchain.com/docs/modules/data_connection/document_loaders/ tiene la capacidad de cargar los siguientes tipos de archivos:\n",
    "+ CSV\n",
    "+ Directorios\n",
    "+ PDF\n",
    "+ Markdown y texto\n",
    "+ HTML\n",
    "+ JSON\n",
    "\n",
    "Importamos un archivo PDF, previamente necesitamos instalar una dependencia\n",
    "```python\n",
    "!pip install pypdf\n",
    "```\n",
    "\n",
    "NOTA: Con la funci칩n `PyPDFDirectoryLoader` pueden cargarse todos los PDFs almancenados en un directorio, si se quiere cargar un 칰nico documento puede emplearse la funci칩n `PyPDFLoader`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0d8637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar en el entorno\n",
    "#%pip install numpy\n",
    "#%pip install langchain\n",
    "#%pip install langchain-community\n",
    "#%pip install pypdf\n",
    "#%pip install sentence_transformers\n",
    "#%pip install langchain_pinecone\n",
    "#%pip install langchain_core\n",
    "#%pip install langchain_huggingface\n",
    "#%pip install huggingface-hub\n",
    "#%pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e07b2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/chatbot/lib/python3.11/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b90e68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_docs = \"docs_ejemplo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad2e1590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'docs_ejemplo/MASTER_INDEX.pdf', 'page': 0}, page_content='Contenido \\nM치ster en Big Data ................................ ................................ ...........................  3 \\nM칍DULO 1 - Fundamentos de tratamiento de datos para Data Science ............ 3 \\nM칍DULO 2 - Business intelligence ................................ ................................ . 5 \\nM칍DULO 3 - Aprendizaje Autom치tico Aplicado (Machine Learning) .................. 8 \\nM칍DULO 4 - Miner칤a de Texto y Procesamiento del Lenguaje Natural (PLN) ..... 10 \\nM칍DULO 5 - Inteligencia de Negocio y Visualizaci칩n ................................ ..... 12 \\nM칍DULO 6 - Infraestructura Big Data ................................ ...........................  15 \\nM칍DULO 7 - Almacenamiento e Integraci칩n de Datos ................................ ... 18 \\nM칍DULO 8 - Valor y Contexto de la Anal칤tica Big Data ................................ ... 20 \\nM칍DULO 9 - Aplicaciones Anal칤ticas. Casos pr치cticos ................................ .. 23 \\nM칍DULO 10 - Trabajo Fin de M치ster en Big Data ................................ ............ 24 \\nM치ster en Inteligencia Artificial y Deep Learning ................................ ............... 25 \\nM칍DULO 1 - Las herramientas del cient칤fico de datos ................................ ... 25 \\nM칍DULO 2 - Impacto y valor del big data ................................ ...................... 27 \\nM칍DULO 3 - Inteligencia artificial para la empresa ................................ ........ 29 \\nM칍DULO 4 - Tecnolog칤as y herramientas big data................................ .......... 32 \\nM칍DULO 5 - El Big Data en la empresa ................................ .........................  34 \\nM칍DULO 6 - Aplicaciones por sectores. Masterclasses, estudio de casos y \\ntalleres pr치cticos ................................ ................................ ........................ 35 \\nM칍DULO 7 - Cloud, MLops, productivizaci칩n de modelos. Introducci칩n a \\nprocess mining ................................ ................................ ...........................  36 \\nM칍DULO 8 - Series temporales y modelos prescriptivos. Optimizaci칩n. Modelos \\nde grafos ................................ ................................ ................................ .... 38 \\nM칍DULO 9 - Deep learning aplicada: NLP y visi칩n artificial ............................  40 \\nM칍DULO 10 - Trabajo Fin de M치ster en IA ................................ ..................... 42 \\nM치ster en Data Science ................................ ................................ .................. 43 \\nM칍DULO 1 - Las herramientas del cient칤fico de datos ................................ ... 43 \\nM칍DULO 2 - La ciencia de datos. T칠cnicas de an치lisis, miner칤a y visualizaci칩n 45 \\nM칍DULO 3 - Estad칤stica para cient칤ficos de datos ................................ ......... 47 \\nM칍DULO 4 - Aprendizaje autom치tico ................................ ...........................  49 \\nM칍DULO 5 - Inteligencia artificial para la empresa ................................ ........ 51 '),\n",
       " Document(metadata={'source': 'docs_ejemplo/MASTER_INDEX.pdf', 'page': 1}, page_content='M칍DULO 6 - Tecnolog칤as y herramientas big data................................ .......... 53 \\nM칍DULO 7 - El trabajo del cient칤fico de datos: pasos y t칠cnicas en el an치lisis. \\nStorytelling ................................ ................................ ................................ . 55 \\nM칍DULO 8 - El proceso de aprendizaje autom치tico: qu칠 es y qu칠 no es. D칩nde \\naplicar la inteligencia artificial ................................ ................................ ..... 56 \\nM칍DULO 9 - Nuevas tendencias: process mining, MLOps, cloud ................... 57 \\nM칍DULO 10 - Trabajo de Fin de Master en Data Science ................................  58 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n '),\n",
       " Document(metadata={'source': 'docs_ejemplo/MASTER_INDEX.pdf', 'page': 2}, page_content='M치ster en Big Data \\nURL: https://www.imf-formacion.com/masters-profesionales/master-big-data-\\nbusiness-intelligence  \\nM칍DULO 1 - Fundamentos de tratamiento de datos para Data \\nScience \\n1. Uso de m치quinas virtuales y shell de comandos \\no Concepto de m치quina virtual box \\no Creaci칩n y configuraci칩n de una m치quina virtual \\no Carga de una m치quina virtual \\no La shell de comandos de linucreaci칩n de scripts \\nUna m치quina virtual (VM) es un entorno de software que simula el hardware de una \\ncomputadora f칤sica, lo que permite ejecutar sistemas operativos y aplicaciones como si se \\ntratara de una m치quina real. VirtualBox es una herramienta popular que permite crear y \\ngestionar m치quinas virtuales, facilitando la ejecuci칩n de varios sistemas operativos en un \\nsolo equipo. La creaci칩n y configuraci칩n de una m치quina virtual implica definir \\npar치metros como la cantidad de memoria, el tipo de procesador y la capacidad del disco. \\nUna vez configurada, la m치quina se puede cargar para realizar tareas como si fuera una \\ncomputadora independiente. La shell de comandos de Linux es un potente entorno para \\nejecutar comandos y crear scripts que permiten automatizar procesos, realizar \\nconfiguraciones y gestionar el sistema de manera eficiente. \\n2. Fundamentos de programaci칩n en Python \\no El lenguaje Python y el entorno Jupyter notebook \\no Elementos b치sicos de Python \\no Estructuras de control \\no Estructuras de datos \\no Funciones \\no Excepciones \\no Importaci칩n de m칩dulos \\no Gesti칩n de ficheros \\nPython es un lenguaje de programaci칩n sencillo y vers치til, ampliamente utilizado tanto \\nen desarrollo de software como en ciencia de datos. El entorno Jupyter Notebook \\nproporciona un espacio interactivo que facilita la programaci칩n en Python, permitiendo a \\nlos usuarios combinar c칩digo con texto y visualizaciones. Los elementos b치sicos de '),\n",
       " Document(metadata={'source': 'docs_ejemplo/MASTER_INDEX.pdf', 'page': 3}, page_content='Python incluyen variables, tipos de datos y operaciones matem치ticas. Las estructuras de \\ncontrol, como bucles y condicionales, permiten dirigir el flujo del programa. Python \\ntambi칠n cuenta con estructuras de datos como listas, diccionarios y tuplas que son \\nfundamentales para organizar la informaci칩n. Adem치s, las funciones permiten dividir el \\nc칩digo en bloques reutilizables, mientras que las excepciones ayudan a gestionar errores. \\nPython facilita la importaci칩n de m칩dulos que ampl칤an su funcionalidad y ofrece  \\nherramientas para la gesti칩n de ficheros, lo cual es crucial para la manipulaci칩n de datos. \\n \\n3. Fundamentos de bases de datos relacionales \\no El modelo relacional \\no SQLite Studio \\no El lenguaje SQL \\nEl modelo relacional es la base de la mayor칤a de las bases de datos modernas, \\npermitiendo organizar la informaci칩n en tablas interconectadas por relaciones. \\nEste enfoque facilita la consulta y manipulaci칩n de datos de manera estructurada. \\nSQLite Studio es una herramienta que permite trabajar con bases de datos SQLite \\nde forma sencilla e intuitiva. El lenguaje SQL (Structured Query Language) es el \\nprincipal medio para interactuar con bases de datos relacionales, proporcionando \\ncomandos para realizar tareas como insertar, actualizar, eliminar y consultar datos. \\nA trav칠s de SQL, se pueden gestionar grandes vol칰menes de datos de forma \\neficiente y segura. \\n4. Fundamentos de tecnolog칤as de internet \\no Formatos de almacenamiento de datos en internet \\no Manipulaci칩n de documentos CSV \\no Manipulaci칩n de documentos JSON \\no Manipulaci칩n de documentos XML \\nEn internet, los datos pueden ser almacenados y compartidos en varios formatos, \\ncomo CSV , JSON y XML. Los archivos CSV (Comma Separated Values) se utilizan \\npara almacenar datos tabulares de forma sencilla y f치cil de manipular. Los \\ndocumentos JSON (JavaScri pt Object Notation) son comunes para el intercambio \\nde informaci칩n entre aplicaciones debido a su estructura clara y ligera. XML \\n(eXtensible Markup Language), aunque menos utilizado que JSON hoy en d칤a, sigue \\nsiendo relevante para ciertos tipos de aplicaci ones y servicios web. La \\nmanipulaci칩n de estos formatos permite a los desarrolladores procesar y \\naprovechar los datos provenientes de diversas fuentes en la web. \\n5. Compartir datos, c칩digo y recursos en repositorios '),\n",
       " Document(metadata={'source': 'docs_ejemplo/MASTER_INDEX.pdf', 'page': 4}, page_content='o Repositorios digitales para compartir \\no La tecnolog칤a GITHUB \\no Uso de Google Drive como repositorio digital \\nLos repositorios digitales permiten compartir c칩digo, datos y otros recursos de \\nmanera eficiente entre desarrolladores y colaboradores. GitHub es una plataforma \\nl칤der para almacenar y gestionar proyectos de software, facilitando la colaboraci칩n \\na trav칠s de l control de versiones y la gesti칩n de cambios. Los usuarios pueden \\ntrabajar juntos en proyectos, realizar revisiones y compartir sus avances de manera \\np칰blica o privada. Google Drive tambi칠n puede ser utilizado como un repositorio \\ndigital, especialmente 칰til para compartir documentos y archivos de forma sencilla \\ny accesible para cualquier colaborador. \\n6. Fundamentos de tratamiento de datos con el stack cient칤fico de Python \\no Gesti칩n de matrices y c치lculo estad칤stico con NUMPY \\no Representaci칩n gr치fica con MATPLOTLIB \\no Manipulaci칩n y an치lisis de datos con PANDAS \\nPython cuenta con un potente ecosistema de herramientas para el tratamiento y \\nan치lisis de datos, conocido como el stack cient칤fico. NumPy es una librer칤a \\nfundamental para la gesti칩n de matrices y la realizaci칩n de c치lculos estad칤sticos, \\nofreciendo funcione s de gran rendimiento para la manipulaci칩n de datos \\nnum칠ricos. Matplotlib es la librer칤a m치s popular para la representaci칩n gr치fica en \\nPython, permitiendo crear visualizaciones que facilitan el entendimiento de los \\ndatos. Pandas, por otro lado, es esencial  para la manipulaci칩n y an치lisis de datos \\nestructurados, facilitando la limpieza y transformaci칩n de grandes vol칰menes de \\ninformaci칩n. Estas herramientas en conjunto permiten a los usuarios realizar desde \\nan치lisis simples hasta tareas complejas de ciencia de datos. \\nM칍DULO 2 - Business intelligence \\n1. Introducci칩n a la inteligencia de negocio \\no Qu칠 es la inteligencia de negocio \\no Importancia de los sistemas de inteligencia de negocio \\no Componentes de los sistemas de BI: arquitectura de inteligencia de \\nnegocio \\no Tipos de an치lisis que se pueden realizar \\no Inteligencia de negocio y anal칤tica de negocio: BI y BA '),\n",
       " Document(metadata={'source': 'docs_ejemplo/MASTER_INDEX.pdf', 'page': 5}, page_content='o Inteligencia de negocio para Big Data \\nLa inteligencia de negocio (BI, por sus siglas en ingl칠s) se refiere al uso de \\ntecnolog칤as y estrategias para analizar datos y convertirlos en informaci칩n \\naccionable que apoye la toma de decisiones empresariales. Los sistemas de BI son \\nfundamentales para m ejorar la eficiencia operativa y la competitividad de las \\norganizaciones. Los componentes de un sistema de BI incluyen una arquitectura \\nque abarca fuentes de datos, almacenamiento, herramientas de an치lisis y \\nvisualizaci칩n. Los an치lisis que se pueden realiz ar incluyen an치lisis descriptivo, \\npredictivo y prescriptivo. Adem치s, existe una diferencia importante entre \\ninteligencia de negocio (BI) y anal칤tica de negocio (BA), siendo BI m치s descriptivo y \\nBA m치s predictivo. BI tambi칠n desempe침a un papel crucial en el  manejo de Big \\nData, ayudando a procesar grandes vol칰menes de datos y proporcionando insights \\nestrat칠gicos. \\n2. Almacenes de datos y bases de datos anal칤ticas \\no Almacenes de datos \\no Herramientas de an치lisis de un almac칠n de datos: OLAP \\no Multidimensionalidad y el modelo multidimensional \\no Desnormalizaci칩n \\no Lenguajes de consulta anal칤sticos: MDX \\nLos almacenes de datos (Data Warehouses) son sistemas dise침ados para \\nalmacenar grandes vol칰menes de informaci칩n de manera organizada y facilitar el \\nan치lisis de los datos hist칩ricos. Las herramientas OLAP (Online Analytical \\nProcessing) permiten explorar los  datos almacenados desde m칰ltiples \\nperspectivas y realizar consultas complejas para identificar patrones y tendencias. \\nEl modelo multidimensional es clave en el an치lisis OLAP , ya que permite organizar \\nla informaci칩n en dimensiones que representan diferente s aspectos del negocio. \\nLa desnormalizaci칩n es una t칠cnica utilizada en almacenes de datos para optimizar \\nla velocidad de consulta. El lenguaje MDX (Multidimensional Expressions) es el \\nlenguaje de consulta empleado para trabajar con datos multidimensionales. \\n3. Herramientas de extracci칩n y carga \\no Qu칠 es el proceso de extracci칩n, transformaci칩n y carga (ETL) \\no Proceso ETL en un proyecto de inteligencia de negocio \\no Tipos de cargas \\no Gobierno del dato y orquestaci칩n '),\n",
       " Document(metadata={'source': 'docs_ejemplo/MASTER_INDEX.pdf', 'page': 6}, page_content='o Buenas pr치cticas \\no Herramientas ETL: Pentaho Data Integration \\nEl proceso de Extracci칩n, Transformaci칩n y Carga (ETL) es esencial en los proyectos \\nde inteligencia de negocio, ya que permite extraer datos de diferentes fuentes, \\ntransformarlos para adecuarlos a los est치ndares y cargarlos en un almac칠n de \\ndatos. Las carg as pueden ser completas o incrementales, dependiendo de las \\nnecesidades del proyecto. El gobierno del dato y la orquestaci칩n son aspectos \\nclave para asegurar la calidad y disponibilidad de los datos durante todo el proceso \\nETL. Pentaho Data Integration es una de las herramientas ETL m치s conocidas, \\npermitiendo llevar a cabo procesos de integraci칩n de datos de manera eficiente. \\nAdem치s, se recomienda seguir buenas pr치cticas para asegurar la integridad y \\ncalidad de los datos en cada etapa del proceso. \\n4. Aplicaciones de inteligencia de negocio \\no Aplicaciones de inteligencia de negocio \\no Herramientas de inteligencia de negocio \\no Herramienta de inteligencia de negocio: Pentaho Business Analytics \\nLas aplicaciones de inteligencia de negocio permiten transformar grandes \\nvol칰menes de datos en informaci칩n comprensible para apoyar la toma de \\ndecisiones. Existen diversas herramientas de BI que permiten realizar an치lisis \\ndetallados y visualizaciones claras. Pentaho Business Analytics es una herramienta \\npoderosa que ofrece un conjunto completo de funciones para an치lisis de datos, \\ndesde la integraci칩n hasta la visualizaci칩n, facilitando la interpretaci칩n de los \\nresultados y el soporte a las decisiones empresariales. \\n5. An치lisis de datos masivos aplicados al negocio \\no Datos externos \\no DEMO \\nEl an치lisis de datos masivos o Big Data permite a las empresas tomar decisiones \\ninformadas al evaluar tanto datos internos como externos. Los datos externos, \\ncomo redes sociales, informaci칩n del mercado y fuentes p칰blicas, complementan \\nlos datos internos para proporcionar una visi칩n m치s completa . Este an치lisis se \\npuede demostrar mediante aplicaciones espec칤ficas que muestran c칩mo los datos \\npueden impactar directamente en las estrategias empresariales. \\n6. Inteligencia de cliente (CRM) \\no CRM '),\n",
       " Document(metadata={'source': 'docs_ejemplo/MASTER_INDEX.pdf', 'page': 7}, page_content='o Inteligencia de cliente \\no Ingesta de datos CRM \\nLos sistemas CRM (Customer Relationship Management) son esenciales para \\ngestionar las relaciones con los clientes y analizar sus comportamientos y \\npreferencias. La inteligencia de cliente se refiere al an치lisis profundo de estos datos \\npara entender mejor a  los clientes y ofrecerles experiencias personalizadas. La \\ningesta de datos CRM implica la recopilaci칩n de informaci칩n de m칰ltiples fuentes \\npara alimentar el sistema y generar estrategias de marketing m치s efectivas y \\nfocalizadas. \\nM칍DULO 3 - Aprendizaje Autom치tico Aplicado (Machine Learning) \\n1. Introducci칩n al aprendizaje autom치tico \\no El proceso de la miner칤a de datos \\no Tipos de aprendizaje autom치tico \\no Introducci칩n a SCIKIT-LEARN y THEANO \\no Uso b치sico de un modelo \\nEl aprendizaje autom치tico es una rama de la inteligencia artificial que se centra en \\nel desarrollo de algoritmos que permiten a las computadoras aprender de los datos \\ny hacer predicciones o tomar decisiones sin ser programadas expl칤citamente para \\ncada tarea. El proceso de la miner칤a de datos consiste en extraer patrones 칰tiles y \\nconocimiento de grandes vol칰menes de datos, utilizando t칠cnicas como el \\npreprocesamiento, la selecci칩n de caracter칤sticas y la modelizaci칩n. Existen \\ndiferentes tipos de aprendizaje autom치tico, entre ellos el aprendizaje supervisado, \\nno supervisado y por refuerzo. Herramientas como SCIKIT -LEARN y THEANO son \\nfundamentales para implementar algoritmos de aprendizaje autom치tico. SCIKIT -\\nLEARN es una librer칤a de Python que facilita el uso d e una amplia variedad de \\nmodelos, mientras que THEANO es una biblioteca para la manipulaci칩n eficiente \\nde tensores, muy 칰til en el desarrollo de redes neuronales. El uso b치sico de un \\nmodelo implica entrenar el algoritmo con datos etiquetados, validar su rendimiento \\ny utilizarlo para hacer predicciones sobre datos nuevos. \\n2. Modelos supervisados \\no Predicci칩n de valores continuos con regresi칩n lineal \\no Clasificaci칩n mediante regresi칩n log칤stica \\no 츼rboles de decisi칩n \\no Otros modelos supervisados '),\n",
       " Document(metadata={'source': 'docs_ejemplo/MASTER_INDEX.pdf', 'page': 8}, page_content='Los modelos supervisados son aquellos que se entrenan utilizando un conjunto de \\ndatos etiquetados, es decir, donde se conoce el resultado deseado. La regresi칩n \\nlineal se utiliza para predecir valores continuos, como por ejemplo el precio de una \\nvivienda en funci칩n de sus caracter칤sticas. Por otro lado, la regresi칩n log칤stica es \\nuna t칠cnica utilizada para problemas de clasificaci칩n binaria, como predecir si un \\ncorreo electr칩nico es spam o no. Los 치rboles de decisi칩n son modelos que \\npermiten clasificar datos dividi칠ndolos en subconjuntos seg칰n sus caracter칤sticas. \\nAdem치s de estos, existen otros modelos supervisados como los vecinos m치s \\ncercanos (KNN) y las m치quinas de vectores de soporte (SVM), que tambi칠n son \\nherramientas poderosas para problemas de clasificaci칩n y regresi칩n \\n3. Modelos no supervisados \\no An치lisis de componentes principales \\no Identificaci칩n de objetos similares con k-means \\no Organizaci칩n de cl칰steres como 치rbol jer치rquico \\no Localizaci칩n de regiones a trav칠s de DBSCAN \\nLos modelos no supervisados se utilizan cuando no se dispone de datos \\netiquetados, y el objetivo es encontrar patrones ocultos o relaciones entre los \\ndatos. El an치lisis de componentes principales (PCA) es una t칠cnica que permite \\nreducir la dimensionalidad de un conjunto de datos, facilitando la visualizaci칩n y el \\nan치lisis. El algoritmo k-means se utiliza para agrupar objetos similares en diferentes \\ncl칰steres, mientras que la organizaci칩n jer치rquica permite crear una estructura de \\ncl칰steres en forma de 치rbol, mostrando relaciones jer치rquicas entre ellos. DBSCAN \\nes otro algoritmo que se utiliza para encontrar regiones densas en los datos y \\nagruparlas, siendo particularmente 칰til para detectar formas arbitrarias y eliminar \\nruido. \\n4. Ingenier칤a de caracter칤sticas y selecci칩n de modelos \\no Diferentes tipos de caracter칤sticas y transformaci칩n \\no Selecci칩n de caracter칤sticas \\no Selecci칩n de modelos \\nLa ingenier칤a de caracter칤sticas es el proceso de transformar los datos brutos en \\ncaracter칤sticas que puedan ser utilizadas por los modelos de aprendizaje. Esto \\npuede incluir t칠cnicas como la normalizaci칩n, la codificaci칩n categ칩rica y la \\nextracci칩n de car acter칤sticas relevantes. La selecci칩n de caracter칤sticas implica \\nelegir aquellas variables que sean m치s relevantes para mejorar la precisi칩n y \\nreducir la complejidad del modelo. Adem치s, la selecci칩n de modelos es un proceso '),\n",
       " Document(metadata={'source': 'docs_ejemplo/MASTER_INDEX.pdf', 'page': 9}, page_content='importante para determinar qu칠 modelo se ajusta mejor a los datos, comparando \\ndiferentes algoritmos y configuraciones para maximizar el rendimiento. \\n5. Modelos conexionistas \\no Perceptrones \\no Redes neuronales \\no Clasificaci칩n de d칤gitos escritos a mano \\nLos modelos conexionistas, tambi칠n conocidos como redes neuronales, est치n \\ninspirados en el funcionamiento del cerebro humano. El perceptr칩n es la unidad \\nb치sica de las redes neuronales y funciona como un clasificador lineal. Las redes \\nneuronales consisten e n m칰ltiples capas de perceptrones que permiten a los \\nmodelos aprender patrones complejos y no lineales. Estos modelos han sido \\nampliamente utilizados en aplicaciones como la clasificaci칩n de d칤gitos escritos a \\nmano, donde una red neuronal es capaz de reconocer n칰meros con gran precisi칩n. \\nLas redes neuronales profundas o deep learning son una extensi칩n de este \\nconcepto y se utilizan en una amplia variedad de tareas complejas, desde el \\nreconocimiento de im치genes hasta el procesamiento del lenguaje natural. \\n6. Reglas de asociaci칩n y market basket analysis \\no Soporte, confianza y lift \\no Algoritmo apriori \\no Otros algoritmos asociativos \\nLas reglas de asociaci칩n son una t칠cnica de miner칤a de datos utilizada para \\ndescubrir relaciones interesantes entre elementos dentro de grandes conjuntos de \\ndatos. En el contexto de market basket analysis, se busca encontrar patrones de \\ncompra que indiquen qu칠 productos suelen ser comprados juntos. Los conceptos \\nde soporte, confianza y lift son fundamentales para evaluar la calidad de las reglas \\ndescubiertas. El algoritmo apriori es uno de los m칠todos m치s conocidos para \\ngenerar estas reglas, pero existen otros algoritmos asociativos que tambi칠n pueden \\nser utilizados dependiendo de la naturaleza de los datos y los objetivos del an치lisis. \\nM칍DULO 4 - Miner칤a de Texto y Procesamiento del Lenguaje \\nNatural (PLN) \\n1. Introducci칩n hist칩rica y tecnol칩gica \\no Contexto hist칩rico \\no Cadenas de procesamiento cl치sicas ')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Abrimos la ruta en la que se encuentran los PDF\n",
    "loader = PyPDFDirectoryLoader(ruta_docs)\n",
    "\n",
    "# Cargamos el PDF \n",
    "raw_pdfs = loader.load()\n",
    "\n",
    "# Vemos que contiene nuestro archivo\n",
    "raw_pdfs[: 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecfb8a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de elementos cargados -->  58\n"
     ]
    }
   ],
   "source": [
    "print(\"Total de elementos cargados --> \", len(raw_pdfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e846bb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El contexto econ칩mico actual destaca la importancia del Big Data para el \n",
      "crecimiento empresarial. El valor del dato radica en su capacidad de generar \n",
      "informaci칩n relevante y estrat칠gica. Existen distintos tipos de datos, desde los \n",
      "estructurados hasta los no estructurados, que cada empresa puede utilizar desde \n",
      "una perspectiva de negocio. Los tipos de anal칤tica se dividen en descriptiva, \n",
      "predictiva y prescriptiva, cada una aportando distintos niveles de conocimiento. La \n",
      "transformaci칩n hacia una organizaci칩n a nal칤tica requiere puntos clave como la \n",
      "cultura de datos y una infraestructura adecuada. El Big Data ayuda a las empresas \n",
      "a ser m치s competitivas y a responder mejor a las demandas del mercado. \n",
      "2. Proyectos de big data \n",
      "o Factores clave \n",
      "o Perfiles \n",
      "o 츼reas de aplicaci칩n \n",
      "o Fases de un proyecto Big Data \n",
      "o Entornos en un proyecto Big Data \n",
      "o Proyectos de datos \n",
      "Un proyecto de Big Data requiere considerar varios factores clave, como la \n",
      "infraestructura tecnol칩gica y el talento especializado. Los perfiles necesarios \n",
      "incluyen cient칤ficos de datos, ingenieros de datos y analistas de negocio. Las 치reas \n",
      "de aplicaci칩n de l Big Data son diversas, abarcando desde marketing hasta \n",
      "producci칩n. Un proyecto de Big Data pasa por diferentes fases, como la definici칩n \n",
      "del problema, la recopilaci칩n de datos, el an치lisis y la implementaci칩n de \n",
      "soluciones. Los entornos en un proyecto de Big Data var칤an seg칰n las necesidades, \n",
      "e incluyen desde sistemas locales hasta soluciones en la nube para garantizar la \n",
      "escalabilidad y disponibilidad de los datos. \n",
      "3. Aplicaciones anal칤ticas por sectores \n",
      "o Google y el buscador \n",
      "o Amazon \n",
      "o Walmart \n",
      "o Recursos humanos \n",
      "o Financiero \n",
      "o Netflix \n"
     ]
    }
   ],
   "source": [
    "print(raw_pdfs[20].page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426ee17b",
   "metadata": {},
   "source": [
    "Vemos que se ha cargado un documento con todas las p치ginas. No obstante, no podemos pasarle toda la informaci칩n de golpe al LLM (por el l칤mite de tokens), sino solamente el trozo m치s similar. El primer paso es dividir el texto en trozos mediante t칠cnicas de _chunking_.\n",
    "\n",
    "Para ir dividiendo la informaci칩n del archivo PDF en peque침os fragmentos volvemos a emplear funciones de LangChain: `RecursiveCharacterTextSplitter()`: https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/recursive_text_splitter/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd198715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide en trozos que no superen el maximo de chunk_size, intentando mantener un sentido\n",
    "# semantico mediante el parametro separators (no cortar en medio de una frase)\n",
    "# Despues, a침ade contexto de chunks anteriores mediante el parametro overlap\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "\n",
    "    separators = [\"\\n\\n\",\"\\n\",\".\",\",\", \";\", \" \"], # \n",
    "    \n",
    "    # Esto asegura que los fragmentos no excedan el l칤mite de 1000 caracteres\n",
    "    # el tama침o de los chunks puede ser inferior si el corte debe ocurrir en un separador\n",
    "    chunk_size = 1000,\n",
    "    \n",
    "    # El solapamiento es crucial para mantener el contexto entre fragmentos: evita que se pierda informaci칩n relevante\n",
    "    chunk_overlap = 300,\n",
    "    \n",
    "    # Funci칩n de longitud que se utiliza para calcular el tama침o del texto.\n",
    "    length_function = len,\n",
    "    \n",
    "    # `add_start_index = True` permite saber desde qu칠 punto del texto original se origin칩 cada fragmento,\n",
    "    # lo cual es 칰til si luego necesitas mapear los resultados generados a la fuente original del documento.\n",
    "    add_start_index = True,\n",
    ")\n",
    "\n",
    "# Dividimos el archivo en fragmentos (chunks)\n",
    "docs_split = text_splitter.split_documents(raw_pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32276156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N칰mero de Chunks producidos desde nuestro PDF -->  154\n"
     ]
    }
   ],
   "source": [
    "print(\"N칰mero de Chunks producidos desde nuestro PDF --> \", len(docs_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59593d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'docs_ejemplo/MASTER_INDEX.pdf', 'page': 7, 'start_index': 0}, page_content='o Inteligencia de cliente \\no Ingesta de datos CRM \\nLos sistemas CRM (Customer Relationship Management) son esenciales para \\ngestionar las relaciones con los clientes y analizar sus comportamientos y \\npreferencias. La inteligencia de cliente se refiere al an치lisis profundo de estos datos \\npara entender mejor a  los clientes y ofrecerles experiencias personalizadas. La \\ningesta de datos CRM implica la recopilaci칩n de informaci칩n de m칰ltiples fuentes \\npara alimentar el sistema y generar estrategias de marketing m치s efectivas y \\nfocalizadas. \\nM칍DULO 3 - Aprendizaje Autom치tico Aplicado (Machine Learning) \\n1. Introducci칩n al aprendizaje autom치tico \\no El proceso de la miner칤a de datos \\no Tipos de aprendizaje autom치tico \\no Introducci칩n a SCIKIT-LEARN y THEANO \\no Uso b치sico de un modelo \\nEl aprendizaje autom치tico es una rama de la inteligencia artificial que se centra en \\nel desarrollo de algoritmos que permiten a las computadoras aprender de los datos')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_split[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "717fd933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o Inteligencia de cliente \n",
      "o Ingesta de datos CRM \n",
      "Los sistemas CRM (Customer Relationship Management) son esenciales para \n",
      "gestionar las relaciones con los clientes y analizar sus comportamientos y \n",
      "preferencias. La inteligencia de cliente se refiere al an치lisis profundo de estos datos \n",
      "para entender mejor a  los clientes y ofrecerles experiencias personalizadas. La \n",
      "ingesta de datos CRM implica la recopilaci칩n de informaci칩n de m칰ltiples fuentes \n",
      "para alimentar el sistema y generar estrategias de marketing m치s efectivas y \n",
      "focalizadas. \n",
      "M칍DULO 3 - Aprendizaje Autom치tico Aplicado (Machine Learning) \n",
      "1. Introducci칩n al aprendizaje autom치tico \n",
      "o El proceso de la miner칤a de datos \n",
      "o Tipos de aprendizaje autom치tico \n",
      "o Introducci칩n a SCIKIT-LEARN y THEANO \n",
      "o Uso b치sico de un modelo \n",
      "El aprendizaje autom치tico es una rama de la inteligencia artificial que se centra en \n",
      "el desarrollo de algoritmos que permiten a las computadoras aprender de los datos\n"
     ]
    }
   ],
   "source": [
    "print(docs_split[20].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f0677f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "957"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_split[20].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123f25c8",
   "metadata": {},
   "source": [
    "## Embeddings <a name=\"embeddings\"></a>\n",
    "\n",
    "Una vez que tenemos separado en peque침os fragmentos nuestro documento PDF, ya podemos obtener los vectores de Word Embeddings sobre el mismo, para posteriormente, poder almacenarlos en Pinecone. \n",
    "\n",
    "Para buscar el modelo adecuado podemos investigar dentro de HuggingFace modelos que soporten creaci칩n de Embeddings con sentence similarity: https://huggingface.co/models?pipeline_tag=sentence-similarity&sort=trending\n",
    "\n",
    "En nuestro caso, vamos a cargar uno de los m치s utilizados `sentence-transformers/all-MiniLM-L6-v2` https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "\n",
    "Este modelo tiene una dimensionalidad de 384.\n",
    "\n",
    "Para poder trabajar con los modelos de sentence-transformers debemos instalar previamente el paquete:\n",
    "```python\n",
    "!pip install sentence_transformers\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b26e6f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el modelo de embeddings\n",
    "\n",
    "huggingface_embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",  \n",
    "    model_kwargs={'device':'cpu'}, \n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e523786a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "con las operaciones de TI para facilitar la implementaci칩n, monitoreo y \n",
      "mantenimiento de modelos en producci칩n. Los requerimientos de MLOps incluyen \n",
      "la automatizaci칩n del proceso de d esarrollo y la integraci칩n continua. MLOps en \n",
      "Azure se implementa a trav칠s de herramientas como Azure Machine Learning, que \n",
      "facilitan la colaboraci칩n y el monitoreo de modelos. AWS ofrece SageMaker, una \n",
      "soluci칩n integral para gestionar el ciclo de vida de los modelos de machine learning. \n",
      "En Google, MLOps se gestiona mediante Vertex AI, que permite a los equipos de \n",
      "datos crear y desplegar modelos de forma eficiente y escalable. \n",
      "M칍DULO 8 - Series temporales y modelos prescriptivos. \n",
      "Optimizaci칩n. Modelos de grafos \n",
      "1. Optimizaci칩n \n",
      "o Descripci칩n de la optimizaci칩n matem치tica \n",
      "o Programaci칩n lineal \n",
      "o Programaci칩n entera \n",
      "o Programaci칩n no lineal \n",
      "o Heur칤sticas y metaheur칤sticas \n",
      "o Optimizaci칩n bajo incertidumbre \n",
      "o Optimizaci칩n y machine learning\n"
     ]
    }
   ],
   "source": [
    "# Comprobamos c칩mo obtiene Embeddings autom치ticamente\n",
    "#  desde una p치gina cualquiera de nuestro documento.\n",
    "print(docs_split[100].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10c7be3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.08006897568702698,\n",
       " -0.028031377121806145,\n",
       " -0.06092718988656998,\n",
       " -0.028301836922764778,\n",
       " 0.002666361164301634,\n",
       " -0.025970494374632835,\n",
       " -0.017113879323005676,\n",
       " 0.024322504177689552,\n",
       " -0.0425584614276886,\n",
       " 0.06241614371538162,\n",
       " -0.0049565932713449,\n",
       " 0.02623717114329338,\n",
       " 0.02730262652039528,\n",
       " -0.012406567111611366,\n",
       " -0.008839382790029049,\n",
       " 0.0734325647354126,\n",
       " 0.00457391794770956,\n",
       " -0.035690370947122574,\n",
       " -0.0934627503156662,\n",
       " -0.010611403733491898,\n",
       " 0.11288634687662125,\n",
       " -0.11038278788328171,\n",
       " -0.10694729536771774,\n",
       " 0.035126861184835434,\n",
       " -0.015215888619422913,\n",
       " -0.0487988106906414,\n",
       " -0.0037630328442901373,\n",
       " 0.03400614112615585,\n",
       " -0.014293663203716278,\n",
       " -0.04002578556537628,\n",
       " -0.02971450611948967,\n",
       " -0.02808339335024357,\n",
       " 0.1056986004114151,\n",
       " 0.05695825815200806,\n",
       " 0.009663194417953491,\n",
       " 0.04797649011015892,\n",
       " 0.04284169524908066,\n",
       " -0.06265434622764587,\n",
       " -0.06185232475399971,\n",
       " 0.006601959001272917,\n",
       " -0.02214927226305008,\n",
       " -0.09500030428171158,\n",
       " -0.046009842306375504,\n",
       " -0.10021927207708359,\n",
       " 0.07873368263244629,\n",
       " 0.003199452767148614,\n",
       " 0.005666960496455431,\n",
       " -0.0655633956193924,\n",
       " -0.023577069863677025,\n",
       " 0.012061298824846745,\n",
       " -0.11429566144943237,\n",
       " -0.15003250539302826,\n",
       " -0.005742546636611223,\n",
       " -0.0069155460223555565,\n",
       " -0.019231004640460014,\n",
       " -0.0012360766995698214,\n",
       " 0.05984386056661606,\n",
       " 0.023140879347920418,\n",
       " 0.0621391236782074,\n",
       " -0.028570838272571564,\n",
       " 0.003305459627881646,\n",
       " -0.07470085471868515,\n",
       " -0.05654311180114746,\n",
       " 0.023461857810616493,\n",
       " 0.00462246872484684,\n",
       " 0.020870458334684372,\n",
       " -0.052751872688531876,\n",
       " -0.030423851683735847,\n",
       " 0.012236373499035835,\n",
       " -0.001337083405815065,\n",
       " 0.006365226116031408,\n",
       " 0.0022606421262025833,\n",
       " -0.11210203915834427,\n",
       " -0.015024891123175621,\n",
       " -0.0076689887791872025,\n",
       " 0.0662563294172287,\n",
       " 0.054574791342020035,\n",
       " 0.03653014078736305,\n",
       " 0.0821017250418663,\n",
       " -0.0908808559179306,\n",
       " -0.01019031647592783,\n",
       " 0.05469305440783501,\n",
       " -0.030412979423999786,\n",
       " 0.041960861533880234,\n",
       " -0.023575210943818092,\n",
       " 0.03543173894286156,\n",
       " -0.03775645047426224,\n",
       " 0.03965159133076668,\n",
       " 0.11211063712835312,\n",
       " -0.05179797112941742,\n",
       " -0.016274139285087585,\n",
       " -0.0002270435361424461,\n",
       " -0.078594870865345,\n",
       " -0.07302257418632507,\n",
       " 0.009135519154369831,\n",
       " 0.04213786497712135,\n",
       " 0.04421398788690567,\n",
       " -0.0963752418756485,\n",
       " 0.034677401185035706,\n",
       " 0.03455488011240959,\n",
       " -0.007909842766821384,\n",
       " 0.014381113462150097,\n",
       " 0.047314129769802094,\n",
       " -0.021926425397396088,\n",
       " -0.0055520785972476006,\n",
       " 0.011994477361440659,\n",
       " 0.01681392453610897,\n",
       " 0.047251760959625244,\n",
       " 0.0576477088034153,\n",
       " -0.006525755859911442,\n",
       " -0.007867181673645973,\n",
       " 0.008657149970531464,\n",
       " 0.009809787385165691,\n",
       " -0.028856681659817696,\n",
       " -0.03288768231868744,\n",
       " 0.03779606521129608,\n",
       " -0.05038411170244217,\n",
       " -0.02631431259214878,\n",
       " 0.003984333015978336,\n",
       " 0.05183664709329605,\n",
       " -0.0007959624635986984,\n",
       " -0.03539294749498367,\n",
       " 0.017648372799158096,\n",
       " -0.05174585431814194,\n",
       " 0.025009043514728546,\n",
       " -0.0321321077644825,\n",
       " -0.056651920080184937,\n",
       " 9.623019933797542e-33,\n",
       " -0.0021543805487453938,\n",
       " -0.02950437180697918,\n",
       " -0.015403227880597115,\n",
       " -0.021878467872738838,\n",
       " 0.07889870554208755,\n",
       " -0.05680856853723526,\n",
       " 0.01715766079723835,\n",
       " -0.046496372669935226,\n",
       " 0.06957042962312698,\n",
       " -0.035886332392692566,\n",
       " -0.13919569551944733,\n",
       " 0.022911662235856056,\n",
       " -0.02637147530913353,\n",
       " 0.07915014773607254,\n",
       " 0.12337474524974823,\n",
       " -0.006814951542764902,\n",
       " 0.07899464666843414,\n",
       " 0.02572214975953102,\n",
       " 0.00868182722479105,\n",
       " 0.024051647633314133,\n",
       " 0.0605536587536335,\n",
       " -0.11685561388731003,\n",
       " -0.01448369026184082,\n",
       " 0.0025886953808367252,\n",
       " 0.021800847724080086,\n",
       " 0.11474546790122986,\n",
       " 0.08180717378854752,\n",
       " 0.015830831602215767,\n",
       " -0.023421183228492737,\n",
       " 0.06577520817518234,\n",
       " 0.04320960119366646,\n",
       " 0.027153946459293365,\n",
       " -0.03836003318428993,\n",
       " 0.030142977833747864,\n",
       " -0.019761918112635612,\n",
       " 0.01031322032213211,\n",
       " -0.055190250277519226,\n",
       " 0.010682246647775173,\n",
       " 0.03955652192234993,\n",
       " 0.022198323160409927,\n",
       " 0.012036841362714767,\n",
       " -0.0046632541343569756,\n",
       " 0.055012788623571396,\n",
       " 0.002827215474098921,\n",
       " -0.031223298981785774,\n",
       " -0.07113049179315567,\n",
       " 0.045993078500032425,\n",
       " -0.052806220948696136,\n",
       " 0.06589268893003464,\n",
       " -0.006808044854551554,\n",
       " -0.04463809356093407,\n",
       " 0.06163838133215904,\n",
       " 0.029845956712961197,\n",
       " -0.10132413357496262,\n",
       " 0.02918156050145626,\n",
       " 0.03847465664148331,\n",
       " 0.02116035670042038,\n",
       " 0.008958072401583195,\n",
       " -0.061019014567136765,\n",
       " 0.03181389346718788,\n",
       " -0.04938530549407005,\n",
       " -0.04318356513977051,\n",
       " 0.05695006251335144,\n",
       " 0.03014708124101162,\n",
       " 0.010677908547222614,\n",
       " -0.05976119637489319,\n",
       " 0.023879515007138252,\n",
       " 0.03403584286570549,\n",
       " 0.09284202754497528,\n",
       " 0.042719025164842606,\n",
       " -0.04233115166425705,\n",
       " -0.02523006685078144,\n",
       " 0.011525561101734638,\n",
       " -0.04493405669927597,\n",
       " -0.017382189631462097,\n",
       " -0.093452088534832,\n",
       " 0.031258244067430496,\n",
       " -0.005023437086492777,\n",
       " -0.03384089842438698,\n",
       " 0.002738487906754017,\n",
       " -0.07940789312124252,\n",
       " 0.009138686582446098,\n",
       " -0.04265854135155678,\n",
       " -0.025192586705088615,\n",
       " 0.016021063551306725,\n",
       " -0.016538644209504128,\n",
       " 0.02723860740661621,\n",
       " 0.007596965879201889,\n",
       " -0.01404799148440361,\n",
       " -0.034756649285554886,\n",
       " -0.09592704474925995,\n",
       " 0.04332248121500015,\n",
       " -0.03837181255221367,\n",
       " -0.022673774510622025,\n",
       " -0.017312107607722282,\n",
       " -1.1829590338235967e-32,\n",
       " 0.01221140194684267,\n",
       " 0.0046541206538677216,\n",
       " -0.018899230286478996,\n",
       " 0.051713019609451294,\n",
       " -0.0023069644812494516,\n",
       " -0.03620622307062149,\n",
       " 0.018599729984998703,\n",
       " -0.045956581830978394,\n",
       " -0.031028511002659798,\n",
       " -0.03331971913576126,\n",
       " -0.02939915843307972,\n",
       " -0.027456600219011307,\n",
       " 0.011729038320481777,\n",
       " 0.036234915256500244,\n",
       " -0.039395350962877274,\n",
       " 0.02827245369553566,\n",
       " -0.06984587758779526,\n",
       " -0.11726516485214233,\n",
       " 0.046006783843040466,\n",
       " -0.006920961197465658,\n",
       " -0.020256828516721725,\n",
       " 0.018352342769503593,\n",
       " -0.014738260768353939,\n",
       " -0.026168208569288254,\n",
       " 0.04592171311378479,\n",
       " -0.07540558278560638,\n",
       " -0.14216551184654236,\n",
       " 0.029305297881364822,\n",
       " -0.02913741208612919,\n",
       " 0.02152918465435505,\n",
       " -0.019823409616947174,\n",
       " -0.0015592416748404503,\n",
       " -0.0008579828427173197,\n",
       " 0.09155052155256271,\n",
       " -0.022794242948293686,\n",
       " -0.022068819031119347,\n",
       " 0.06894861906766891,\n",
       " -0.033982809633016586,\n",
       " 0.058851152658462524,\n",
       " 0.0851554423570633,\n",
       " 0.12627486884593964,\n",
       " -0.015224606730043888,\n",
       " -0.03186561167240143,\n",
       " -0.03546390309929848,\n",
       " -0.022015441209077835,\n",
       " 0.03809191286563873,\n",
       " -0.07541737705469131,\n",
       " -0.019168173894286156,\n",
       " 0.011036413721740246,\n",
       " -0.06893310695886612,\n",
       " 0.005459750536829233,\n",
       " 0.061074670404195786,\n",
       " -0.06687629967927933,\n",
       " 0.005962647031992674,\n",
       " -0.04204920306801796,\n",
       " -0.025605376809835434,\n",
       " -0.005793281365185976,\n",
       " 0.011599252931773663,\n",
       " -0.12517261505126953,\n",
       " 0.03217533975839615,\n",
       " -0.033606525510549545,\n",
       " -0.0349428728222847,\n",
       " 0.020281078293919563,\n",
       " -0.047187596559524536,\n",
       " 0.043714191764593124,\n",
       " 0.10875706374645233,\n",
       " -0.012449686415493488,\n",
       " -0.01682739332318306,\n",
       " -0.06074211746454239,\n",
       " -0.02725645899772644,\n",
       " 0.06172379478812218,\n",
       " -0.004268968943506479,\n",
       " -0.06448821723461151,\n",
       " 0.038507893681526184,\n",
       " -0.04269278421998024,\n",
       " -0.05016564950346947,\n",
       " -0.08342456817626953,\n",
       " -0.02097170799970627,\n",
       " -0.04646151885390282,\n",
       " -0.048578567802906036,\n",
       " -0.05960388854146004,\n",
       " -0.016359535977244377,\n",
       " 0.013975519686937332,\n",
       " 0.025250477716326714,\n",
       " -0.06712890416383743,\n",
       " 0.049710098654031754,\n",
       " 0.0024362823460251093,\n",
       " 0.06826707720756531,\n",
       " -0.027900049462914467,\n",
       " -0.04585183039307594,\n",
       " -0.09177248924970627,\n",
       " 0.053578950464725494,\n",
       " -0.050621289759874344,\n",
       " 0.11747052520513535,\n",
       " -0.06925536692142487,\n",
       " -6.10056574146256e-08,\n",
       " -0.0371541753411293,\n",
       " 0.040696773678064346,\n",
       " 0.040354035794734955,\n",
       " -0.01622537337243557,\n",
       " 0.04699559509754181,\n",
       " 0.019617965444922447,\n",
       " -0.04530094936490059,\n",
       " 0.05865098908543587,\n",
       " 0.04438238963484764,\n",
       " 0.003284966107457876,\n",
       " 0.0035646643955260515,\n",
       " -0.06941672414541245,\n",
       " -0.018105436116456985,\n",
       " 0.023253895342350006,\n",
       " 0.08720023930072784,\n",
       " 0.05730193853378296,\n",
       " 0.09991233795881271,\n",
       " 0.028379878029227257,\n",
       " -0.057372212409973145,\n",
       " -0.05295563116669655,\n",
       " 0.09086543321609497,\n",
       " 0.02476928010582924,\n",
       " -0.05235994979739189,\n",
       " -0.021600842475891113,\n",
       " 0.05795912444591522,\n",
       " -0.06591548025608063,\n",
       " -0.09527725726366043,\n",
       " 0.05880162864923477,\n",
       " -0.05760294198989868,\n",
       " 0.034958887845277786,\n",
       " -0.006132709328085184,\n",
       " 0.06237160414457321,\n",
       " 0.08897583186626434,\n",
       " -0.02478056587278843,\n",
       " 0.043692559003829956,\n",
       " 0.062376804649829865,\n",
       " 0.011363865807652473,\n",
       " -0.007399153430014849,\n",
       " 0.023012537509202957,\n",
       " -0.021333981305360794,\n",
       " 0.04476548358798027,\n",
       " 0.06858175247907639,\n",
       " -0.08365790545940399,\n",
       " -0.028195470571517944,\n",
       " 0.0021929654758423567,\n",
       " -0.03758910298347473,\n",
       " 0.04926944524049759,\n",
       " -0.06925532966852188,\n",
       " -0.02077317237854004,\n",
       " 0.07714155316352844,\n",
       " -0.009194398298859596,\n",
       " -0.010403497144579887,\n",
       " 0.023080039769411087,\n",
       " 0.06554602086544037,\n",
       " 0.044686850160360336,\n",
       " 0.023279301822185516,\n",
       " 0.0502752959728241,\n",
       " -0.16928516328334808,\n",
       " 0.05820893123745918,\n",
       " 0.09495420008897781,\n",
       " 0.07013875246047974,\n",
       " 0.02290070243179798,\n",
       " 0.029623035341501236,\n",
       " -0.08678081631660461]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_embeddings.embed_query(docs_split[100].page_content) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b026d1",
   "metadata": {},
   "source": [
    "## Carga de los Embeddings en Pinecone <a name=\"persist\"></a> \n",
    "\n",
    "Para insertar documentos en Pinecone vuelve a ayudarnos LangChain, ya que tiene integraciones directas con m칰ltiples bases de datos vectoriales https://python.langchain.com/docs/modules/data_connection/vectorstores/\n",
    "\n",
    "```python\n",
    "pip install langchain-core \n",
    "pip install langchain-pinecone\n",
    "```\n",
    "\n",
    "La funci칩n que vamos a utilizar nos permitir치, de una sola vez (1) convertir los textos a embedding (con el modelo cargado antes) y (2) subir los embeddings al 칤ndice de Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95ba3f7",
   "metadata": {},
   "source": [
    "**NOTA**: En este punto, debo tener creado un 칤ndice en Pinecone con las dimensiones requeridas para mi modelo de embedding (en este caso, 384) + haber guardado el nombre del nuevo 칤ndice en el fichero .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e047b8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e484d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta funcion permitira pasar cada documento por el embedding y cargarlo en el indice\n",
    "\n",
    "docs = PineconeVectorStore.from_documents(\n",
    "    documents  = docs_split, \n",
    "    embedding  = huggingface_embeddings, \n",
    "    index_name = os.environ[\"INDEX_CHATBOT\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dd40ec",
   "metadata": {},
   "source": [
    "## LLM y generaci칩n de prompts <a name=\"hf\"></a> \n",
    "\n",
    "Lo primero que deberemos conseguir ser치 la API TOKEN de Huggingface. Posteriormente, empleamos la funci칩n `HuggingFaceHub` a la cu치l le pasaremos principalmente como par치metro (en `repo_id`) el nombre del modelo. Para poder obtener toda la lista de modelos p칰blicos de Huggingface, demos seleccionar en Models -> Natural Language Processing - Text Generation.\n",
    "\n",
    "En nuestro caso, vamos a usar una de las mejores propuestas en cuanto a modelos p칰blicos __Mistral__ https://huggingface.co/mistralai con el modelo `Mistral-7B-Instruct-v0.2`. https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2\n",
    "\n",
    "Importante: Debemos aceptar los t칠rminos de licencia para poder utilizar el modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f019240c",
   "metadata": {},
   "source": [
    "Guardamos la API KEY de hugging face en nuestro fichero .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "608278aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b04ce705",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGINGFACEHUB_API_TOKEN = os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n",
    "\n",
    "llm = HuggingFaceEndpoint(    \n",
    "    huggingfacehub_api_token = HUGGINGFACEHUB_API_TOKEN,\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\", #\"meta-llama/Llama-3.2-1B\", #\"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "    temperature = 0.5, # a mayor temperatura, mayor creatividad y menos conservador\n",
    "    model_kwargs={\"max_length\":2048})\n",
    "                  #\"max_new_tokens\": 500})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840ded93",
   "metadata": {},
   "source": [
    "Una vez definido nuestro LLM, podemos hacer una peque침a prueba, para pasarle una consulta (prompt) al llm utilizaremos funciones como `run` o `invoke`\n",
    "\n",
    "Antes de usar nuestra BBDD vectorial como contexto, hacemos una prueba solo con el LLM (responder치 en base a la informaci칩n con la que fue entrenado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "710eca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        Hola, dame las caracter칤sticas de Python \n",
    "        \"\"\" \n",
    "llm.client.api_url = \"mistralai/Mistral-7B-Instruct-v0.2\" # hay veces que pierde donde est치 el repo (no siempre es necesario pero se hace por si acaso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9f2d50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Python es una lenguaje de programaci칩n de alto nivel, interpretado y de sintaxis limpia.\n",
      "        2. Es ampliamente utilizado en la web, ciencia de datos, automatizaci칩n y muchas otras 치reas.\n",
      "        3. Es altamente port치til y puede ser ejecutado en muchas plataformas diferentes, como Windows, MacOS, Linux, etc.\n",
      "        4. Python es conocido por su sintaxis simple y clara, lo que lo hace ideal para principiantes y expertos.\n",
      "        5. Python tiene una amplia biblioteca est치ndar y una comunidad activa de desarrolladores que crean paquetes adicionales.\n",
      "        6. Es altamente escalable y se puede usar para desarrollar aplicaciones peque침as y grandes.\n",
      "        7. Python es din치mico, lo que significa que puede modificar el programa en ejecuci칩n.\n",
      "        8. Python tiene un buen soporte para multihilo y multiprocesamiento, lo que lo hace ideal para aplicaciones que requieren mucha computaci칩n.\n",
      "        9. Python tiene un buen soporte para integraci칩n con otros lenguajes y herramientas, lo que lo hace vers치til.\n",
      "        10. Python tiene un buen soporte para IDE (Entorno Integrado de Desarrollo), lo que facilita el desarrollo de aplicaciones.\n",
      "        11. Python tiene un buen soporte para documentaci칩n, lo que facilita la comprensi칩n y el aprendizaje del lenguaje.\n",
      "        12. Python es gratuito y libre de uso, lo que lo hace accesible a todos.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(query)) # despues regularemos el tama침o del mensaje de salida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de2b99e",
   "metadata": {},
   "source": [
    "Como vemos, la respuesta es gen칠rica ya que todav칤a no estamos integrando nuestra base de conocimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa2d3e0",
   "metadata": {},
   "source": [
    "Para interactuar con nuestra base de conocimento debemos elaborar una funci칩n _retriever_, que ser치 capaz de buscar por similaridad documentos (en nuestro caso, a trav칠s de los documentos ya cargados en Pinecone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db67fe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el vector store\n",
    "vectorstore = PineconeVectorStore(\n",
    "    index_name=os.environ[\"INDEX_CHATBOT\"],\n",
    "    pinecone_api_key=os.environ[\"PINECONE_API_KEY\"],\n",
    "    embedding=huggingface_embeddings,\n",
    ")\n",
    "\n",
    "\n",
    "# Crear el retriever a partir del VectorStore\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\", \n",
    "    search_kwargs={\"k\": 3} # Consultas basadas en los 3 mejores resultados\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb57c472",
   "metadata": {},
   "source": [
    "Creamos el Prompt, donde no solo hay que indicarle la pregunta sino todas las instrucciones que debe tener en cuenta (contexto a utilizar, memoria, si quieres que no invente informaci칩n...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea943b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Eres un comercial especializado de una escuela de negocios que asesora a futuros alumnos sobre m치sters.\n",
    "Contesta la pregunta basandote en el contexto (delimitado por <ctx> </ctx>) y en el hist칩rico del chat (delimitado por <hs></hs>) de abajo.\n",
    "1. Da una respuesta lo m치s concisa posible.\n",
    "2. Si la respuesta no aparece en el contexto proporcionado di que no tienes la informaci칩n.\n",
    "3. Lim칤tate a responder a la pregunta y proporciona solo la respuesta 칰til\n",
    "\n",
    "Informaci칩n proporcionada\n",
    "-------\n",
    "<ctx>\n",
    "Contexto: {context}\n",
    "</ctx>\n",
    "-------\n",
    "<hs>\n",
    "Hist칩rico: {chat_history}\n",
    "</hs>\n",
    "-------\n",
    "Pregunta: {question}\n",
    "Respuesta 칰til:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    " template=prompt_template, input_variables=[\"context\",  \"chat_history\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c63ab2",
   "metadata": {},
   "source": [
    "Ahora, ya solo nos queda definir nuestro chatbot a trav칠s de la funci칩n que debe recibir el prompt, el llm y el objeto retriever `RetrievalQA.from_chain_type()`. QA es para preguntas y respuestas, no obstante, hay otro tipo de cadenas para por ejemplo devolver c칩digo.\n",
    "Al asistente, habr치 que pasarle tanto la pregunta como el par치metro opcional `memory`, que definiremos previamente con la funci칩n `ConversationBufferMemory`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5371c742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ms/b0wp19xj6t95pygkb1yqjh2c0000gn/T/ipykernel_3822/1321285784.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "       input_key=\"question\"\n",
    ")\n",
    "\n",
    "retrievalQA = RetrievalQA.from_chain_type(\n",
    "llm=llm,\n",
    "chain_type=\"stuff\",\n",
    "retriever=retriever,\n",
    "return_source_documents=True,\n",
    "chain_type_kwargs={\"prompt\": PROMPT,\n",
    "               \"memory\": memory})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b64b314a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Business Intelligence (BI) se aborda en el m칩dulo 2 de la estructura de estudios proporcionada. En este m칩dulo, se introduce la concepto de BI, su importancia, los componentes de los sistemas de BI, y los tipos de an치lisis que se pueden realizar. Adem치s, se menciona que Pandas es una herramienta importante para la manipulaci칩n y an치lisis de datos estructurados en el contexto de BI. Por lo tanto, el m칩dulo 2 es el lugar adecuado para aprender sobre Business Intelligence.\n"
     ]
    }
   ],
   "source": [
    "query = \"en qu칠 m칩dulo puedo aprender business intelligence?\"\n",
    "\n",
    "respuesta = retrievalQA.invoke({\"query\": query})\n",
    "print(respuesta['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e8cb6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'en qu칠 m칩dulo puedo aprender business intelligence?',\n",
       " 'result': 'El Business Intelligence (BI) se aborda en el m칩dulo 2 de la estructura de estudios proporcionada. En este m칩dulo, se introduce la concepto de BI, su importancia, los componentes de los sistemas de BI, y los tipos de an치lisis que se pueden realizar. Adem치s, se menciona que Pandas es una herramienta importante para la manipulaci칩n y an치lisis de datos estructurados en el contexto de BI. Por lo tanto, el m칩dulo 2 es el lugar adecuado para aprender sobre Business Intelligence.',\n",
       " 'source_documents': [Document(id='751b498a-dbc2-41f9-9dce-5553c954ed39', metadata={'page': 12.0, 'source': 'docs_ejemplo/MASTER_INDEX.pdf', 'start_index': 0.0}, page_content='o Estructura de un sistema de business intelligence \\no Datos, informaci칩n y conocimiento \\no Alfabetizaci칩n de datos \\nEl business intelligence (BI) se refiere al conjunto de procesos, tecnolog칤as y \\nherramientas que convierten los datos en informaci칩n 칰til para apoyar la toma de \\ndecisiones empresariales. Un sistema de BI se estructura a partir de varias capas \\nque incluyen la recopilaci칩n, integraci칩n, an치lisis y presentaci칩n de los datos. Los \\ndatos se transforman en informaci칩n y posteriormente en conocimiento para guiar \\ndecisiones estrat칠gicas. La alfabetizaci칩n de datos es crucial en este contexto, ya \\nque permite que los usuarios comprendan y trabajen con los datos de forma \\nefectiva. \\n2. BI vs. reporting tradicional \\no Paradigma actual \\no Reporting tradicional vs. BI \\no Modern BI vs. Traditional BI \\no Encaje de BI con big data \\nEl paradigma actual de BI ha evolucionado considerablemente respecto al \\nreporting tradicional. Mientras que el reporting tradicional se centra en la'),\n",
       "  Document(id='d5a83b9e-056c-4c03-b500-7b260719008b', metadata={'page': 11.0, 'source': 'docs_ejemplo/MASTER_INDEX.pdf', 'start_index': 1464.0}, page_content='traducci칩n autom치tica, la generaci칩n de texto y los sistemas de recomendaci칩n. \\nUn ejemplo pr치ctico de PLN son los asistentes conversacionales, que utilizan \\nt칠cnicas avanzadas para com prender las consultas del usuario y proporcionar \\nrespuestas relevantes. Estas tecnolog칤as est치n cada vez m치s presentes en nuestras \\nvidas diarias, mejorando la interacci칩n entre humanos y m치quinas. \\nM칍DULO 5 - Inteligencia de Negocio y Visualizaci칩n \\n1. Introducci칩n al business intelligence \\no Business intelligence'),\n",
       "  Document(id='eb9fc5dd-56e6-4221-aa27-112159dbc9c2', metadata={'page': 4.0, 'source': 'docs_ejemplo/MASTER_INDEX.pdf', 'start_index': 1428.0}, page_content='datos. Pandas, por otro lado, es esencial  para la manipulaci칩n y an치lisis de datos \\nestructurados, facilitando la limpieza y transformaci칩n de grandes vol칰menes de \\ninformaci칩n. Estas herramientas en conjunto permiten a los usuarios realizar desde \\nan치lisis simples hasta tareas complejas de ciencia de datos. \\nM칍DULO 2 - Business intelligence \\n1. Introducci칩n a la inteligencia de negocio \\no Qu칠 es la inteligencia de negocio \\no Importancia de los sistemas de inteligencia de negocio \\no Componentes de los sistemas de BI: arquitectura de inteligencia de \\nnegocio \\no Tipos de an치lisis que se pueden realizar \\no Inteligencia de negocio y anal칤tica de negocio: BI y BA')]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respuesta # tambien devuelve los trozos de documento mas similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f521af3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S칤, el m칩dulo 2 de la estructura de estudios incluye el tema de la ciencia de datos, donde se abordan t칠cnicas de an치lisis, miner칤a y visualizaci칩n de datos. Dentro de este tema, se estudian diferentes tipos de bases de datos, incluyendo bases de datos relacionales y NoSQL, as칤 como sus respectivas caracter칤sticas y aplicaciones.\n"
     ]
    }
   ],
   "source": [
    "query = \"en ese modulo se estudian bases de datos?\"\n",
    "\n",
    "respuesta = retrievalQA.invoke({\"query\": query})\n",
    "\n",
    "print(respuesta['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ad4b92",
   "metadata": {},
   "source": [
    "Para obtener los documentos utilizados para elaborar la respuesta, podemos crear una funci칩n que nos extraiga de forma estructurada la p치gina y el texto obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa156af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_doc_sources(respuesta):\n",
    "\n",
    "    lista_docs = respuesta['source_documents']\n",
    "\n",
    "    documentos = [\"P치gina: \" + str(elemento.metadata['page']) + \" - Contenido: \" + elemento.page_content for elemento in lista_docs]\n",
    "\n",
    "    return documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1529079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P치gina: 44.0 - Contenido: presentaciones y an치lisis exploratorios en los que se busca una mayor interacci칩n \\ncon los datos. \\nM칍DULO 2 - La ciencia de datos. T칠cnicas de an치lisis, miner칤a y \\nvisualizaci칩n \\n1. El ciclo de vida del dato \\no Definici칩n de ciencia de datos \\no El ciclo de vida de los datos \\no Definici칩n de objetivos en un proyecto de datos \\no Identificaci칩n de los datos necesarios \\no Preparaci칩n y preproceso \\no An치lisis y modelado \\no Validaci칩n y prueba \\nLa ciencia de datos se refiere al uso de t칠cnicas y herramientas para extraer \\ninformaci칩n y conocimiento de los datos. El ciclo de vida del dato comienza con la \\ndefinici칩n de los objetivos de un proyecto de datos, lo que implica entender el \\nproblema a reso lver y los resultados esperados. Luego, se identifican los datos \\nnecesarios para cumplir esos objetivos. La preparaci칩n y preproceso de datos \\nincluyen la limpieza, transformaci칩n y estructuraci칩n de los datos para su an치lisis.',\n",
       " 'P치gina: 17.0 - Contenido: o Limitaciones de las bases de datos relacionales \\no Bases de datos NOSQL \\no Bases de datos orientadas hacia agregados \\no Modelos de distribuci칩n en las bases de datos NOSQL \\no El teorema CAP \\no Cu치ndo usar NOSQL o SQL \\nLos datos masivos o Big Data requieren soluciones de almacenamiento y \\nprocesamiento m치s flexibles que las bases de datos tradicionales. Las bases de \\ndatos relacionales son 칰tiles para datos estructurados, pero presentan limitaciones \\ncuando se manejan grandes vol칰menes o datos no estructurados. En estos casos, \\nlas bases de datos NoSQL son una opci칩n eficaz. Estas bases de datos est치n \\norientadas hacia agregados, lo que permite almacenar datos complejos de forma \\neficiente. Adem치s, los modelos de distribuci칩n e n NoSQL permiten escalar \\nf치cilmente. El teorema CAP explica las caracter칤sticas fundamentales de los \\nsistemas distribuidos: consistencia, disponibilidad y tolerancia a particiones. Elegir',\n",
       " 'P치gina: 53.0 - Contenido: nube de forma eficiente, proporcionando un entorno colaborativo para el an치lisis \\nde datos. \\n3. Bases de datos NoSQL \\no Hbase \\no MongoDB \\no Cassandra \\no Modelos de BBDD orientadas a grafos \\nLas bases de datos NoSQL se utilizan para almacenar y gestionar datos no \\nestructurados o semi -estructurados. HBase es una base de datos NoSQL que se \\nejecuta sobre HDFS y es adecuada para acceso aleatorio a grandes vol칰menes de \\ndatos. MongoDB es una base de datos orientada a documentos, ideal para manejar \\ndatos flexibles y sin una estructura definida. Cassandra es una base de datos \\ndistribuida y orientada a columnas que se destaca por su alta disponibilidad y \\nescalabilidad. Tambi칠n existen bases de datos ori entadas a grafos, como Neo4j, \\nque permiten modelar y consultar relaciones complejas entre datos de manera \\neficiente. \\n4. Plataformas Cloud \\no Servicios cloud']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obtener_doc_sources(respuesta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d147950c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='en qu칠 m칩dulo puedo aprender business intelligence?', additional_kwargs={}, response_metadata={}), AIMessage(content='El Business Intelligence (BI) se aborda en el m칩dulo 2 de la estructura de estudios proporcionada. En este m칩dulo, se introduce la concepto de BI, su importancia, los componentes de los sistemas de BI, y los tipos de an치lisis que se pueden realizar. Adem치s, se menciona que Pandas es una herramienta importante para la manipulaci칩n y an치lisis de datos estructurados en el contexto de BI. Por lo tanto, el m칩dulo 2 es el lugar adecuado para aprender sobre Business Intelligence.', additional_kwargs={}, response_metadata={}), HumanMessage(content='en ese modulo se estudian bases de datos?', additional_kwargs={}, response_metadata={}), AIMessage(content='S칤, el m칩dulo 2 de la estructura de estudios incluye el tema de la ciencia de datos, donde se abordan t칠cnicas de an치lisis, miner칤a y visualizaci칩n de datos. Dentro de este tema, se estudian diferentes tipos de bases de datos, incluyendo bases de datos relacionales y NoSQL, as칤 como sus respectivas caracter칤sticas y aplicaciones.', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ae0c8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.clear() # para resetear memoria (si no se hace, se puede superar el limite de tokens y da error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18cfeb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_prueba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
